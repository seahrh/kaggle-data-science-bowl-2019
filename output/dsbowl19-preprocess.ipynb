{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit           : None\n",
      "\n",
      "pandas           : 0.25.3\n",
      "numpy            : 1.18.1\n",
      "pytz             : 2019.3\n",
      "dateutil         : 2.8.1\n",
      "pip              : 19.3.1\n",
      "setuptools       : 44.0.0\n",
      "Cython           : None\n",
      "pytest           : None\n",
      "hypothesis       : None\n",
      "sphinx           : None\n",
      "blosc            : None\n",
      "feather          : None\n",
      "xlsxwriter       : None\n",
      "lxml.etree       : None\n",
      "html5lib         : None\n",
      "pymysql          : None\n",
      "psycopg2         : None\n",
      "jinja2           : 2.10.3\n",
      "IPython          : 7.11.1\n",
      "pandas_datareader: None\n",
      "bs4              : None\n",
      "bottleneck       : None\n",
      "fastparquet      : None\n",
      "gcsfs            : None\n",
      "lxml.etree       : None\n",
      "matplotlib       : 3.1.2\n",
      "numexpr          : None\n",
      "odfpy            : None\n",
      "openpyxl         : None\n",
      "pandas_gbq       : None\n",
      "pyarrow          : 0.15.1\n",
      "pytables         : None\n",
      "s3fs             : None\n",
      "scipy            : 1.4.1\n",
      "sqlalchemy       : None\n",
      "tables           : None\n",
      "xarray           : None\n",
      "xlrd             : None\n",
      "xlwt             : None\n",
      "xlsxwriter       : None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import gc\n",
    "import warnings\n",
    "from math import sqrt\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer, mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log(str):\n",
    "    os.system(f'echo \\\"{str}\\\"')\n",
    "    print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_ROOT = '../input/data-science-bowl-2019'\n",
    "JOIN_KEY = ['installation_id', 'game_session', 'title']\n",
    "TARGET = 'accuracy_group'\n",
    "FEATURES = {\n",
    "    'event_id', \n",
    "    'game_session', \n",
    "    'timestamp', \n",
    "    'installation_id', \n",
    "    'event_count',\n",
    "    'event_code', \n",
    "    'game_time', \n",
    "    'title', \n",
    "    'type', \n",
    "    'world',\n",
    "    'event_data'\n",
    "}\n",
    "EVENT_CODES = ['2000', '2010', '2020', '2025', '2030', '2035', '2040', '2050', '2060', '2070', '2075', '2080', '2081', '2083', '3010', '3020', '3021', '3110', '3120', '3121', '4010', '4020', '4021', '4022', '4025', '4030', '4031', '4035', '4040', '4045', '4050', '4070', '4080', '4090', '4095', '4100', '4110', '4220', '4230', '4235', '5000', '5010']\n",
    "SEED = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init():\n",
    "    # Characters such as empty strings '' or numpy.inf are considered NA values\n",
    "    pd.set_option('use_inf_as_na', True)\n",
    "    pd.set_option('display.max_columns', 999)\n",
    "    pd.set_option('display.max_rows', 999)\n",
    "    \n",
    "    \n",
    "_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM_VALUES=[0.01227824739797545, 0.11239886108023578, 0.39283736155074256, 0.683864273453267, 0.13869093321463077, 0.11244356285938728, 0.23180235707395025, 0.7575924853950116, 0.1474012209602784, 0.7406551989400061, 0.6621666555152632, 0.13657852434493012, 0.5356617475477887, 0.4477509299372836, 0.41257008317805066, 0.9963436915955056, 0.0931113892655685, 0.02036645837312856, 0.9398019156431335, 0.40294581161091647]\n"
     ]
    }
   ],
   "source": [
    "RANDOM_VALUES = []\n",
    "for _ in range(4000):\n",
    "    RANDOM_VALUES.append(random.random())\n",
    "    \n",
    "_log(f'RANDOM_VALUES={RANDOM_VALUES[:20]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/data-science-bowl-2019/train_labels.csv\n",
      "../input/data-science-bowl-2019/test.csv\n",
      "../input/data-science-bowl-2019/train.csv\n",
      "../input/data-science-bowl-2019/train_labels.csv.zip\n",
      "../input/data-science-bowl-2019/test.csv.zip\n",
      "../input/data-science-bowl-2019/train.csv.zip\n"
     ]
    }
   ],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "for dirname, _, filenames in os.walk(INPUT_ROOT):\n",
    "    for filename in filenames:\n",
    "        _log(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17690 entries, 0 to 17689\n",
      "Data columns (total 4 columns):\n",
      "game_session       17690 non-null object\n",
      "installation_id    17690 non-null object\n",
      "title              17690 non-null object\n",
      "accuracy_group     17690 non-null int64\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 552.9+ KB\n",
      "CPU times: user 42.9 s, sys: 7.7 s, total: 50.6 s\n",
      "Wall time: 52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_raw = pd.read_csv(f'{INPUT_ROOT}/train.csv', usecols=FEATURES)\n",
    "train_labels = pd.read_csv(f'{INPUT_ROOT}/train_labels.csv', usecols=JOIN_KEY + [TARGET])\n",
    "test_raw = pd.read_csv(f'{INPUT_ROOT}/test.csv', usecols=FEATURES)\n",
    "train_labels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add labels to train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_unlabelled_data(train_raw, train_labels):\n",
    "    return train_raw[train_raw['installation_id'].isin(train_labels['installation_id'].unique())]\n",
    "\n",
    "\n",
    "train_raw = _remove_unlabelled_data(train_raw, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.66 s, sys: 831 ms, total: 4.49 s\n",
      "Wall time: 4.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def _add_labels(train_raw, train_labels, on):\n",
    "    return pd.merge(train_raw, train_labels, on=on, how='left')\n",
    "\n",
    "\n",
    "train_raw = _add_labels(train_raw, train_labels, on=JOIN_KEY)\n",
    "del train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract event data JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [08:17<00:00, 62.16s/it]\n",
      "100%|██████████| 2/2 [01:12<00:00, 36.37s/it]\n"
     ]
    }
   ],
   "source": [
    "def _concat_columns(df1, df2):\n",
    "    \"\"\"Concatenate the columns of two pandas dataframes in the order of the operands.\n",
    "    Both dataframes must have the same number of rows.\n",
    "    \"\"\"\n",
    "    assert len(df1) == len(df2)\n",
    "    res = pd.concat([df1, df2.reindex(df1.index)], axis=1, join='inner')\n",
    "    assert len(res) == len(df1)\n",
    "    return res\n",
    "    \n",
    "\n",
    "def _extract_event_data(df, keep_cols, chunk_size=1000000):\n",
    "    res = pd.DataFrame()\n",
    "    _len = len(df)\n",
    "    for i in tqdm(range(0, _len, chunk_size)):\n",
    "        if i + chunk_size < _len:\n",
    "            chunk = df[i:i + chunk_size].copy()\n",
    "        else:\n",
    "            chunk = df[i:].copy()\n",
    "        ed = pd.io.json.json_normalize(chunk['event_data'].apply(json.loads)).add_prefix('ed.')\n",
    "        ed = ed[keep_cols].astype(np.float32)\n",
    "        chunk = _concat_columns(chunk, ed)\n",
    "        # sort=False because not all rows have same fields in event_data\n",
    "        res = pd.concat([res, chunk], ignore_index=True, sort=False)\n",
    "    # this line is too slow and OOM error!\n",
    "    #res[keep_cols] = res[keep_cols].fillna(-1).astype(np.float32)\n",
    "    assert len(df) == len(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "keep_cols = ['ed.duration', 'ed.level', 'ed.round', 'ed.correct', 'ed.misses','ed.weight', 'ed.total_duration']\n",
    "#keep_cols = ['ed.identifier', 'ed.duration', 'ed.level', 'ed.round', 'ed.correct', 'ed.misses','ed.weight', 'ed.total_duration', 'ed.source']\n",
    "train_raw = _extract_event_data(train_raw, keep_cols)\n",
    "test_raw = _extract_event_data(test_raw, keep_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1156414 entries, 0 to 1156413\n",
      "Data columns (total 18 columns):\n",
      "event_id             1156414 non-null object\n",
      "game_session         1156414 non-null object\n",
      "timestamp            1156414 non-null object\n",
      "event_data           1156414 non-null object\n",
      "installation_id      1156414 non-null object\n",
      "event_count          1156414 non-null int64\n",
      "event_code           1156414 non-null int64\n",
      "game_time            1156414 non-null int64\n",
      "title                1156414 non-null object\n",
      "type                 1156414 non-null object\n",
      "world                1156414 non-null object\n",
      "ed.duration          336619 non-null float32\n",
      "ed.level             84208 non-null float32\n",
      "ed.round             598718 non-null float32\n",
      "ed.correct           69806 non-null float32\n",
      "ed.misses            23658 non-null float32\n",
      "ed.weight            50353 non-null float32\n",
      "ed.total_duration    170228 non-null float32\n",
      "dtypes: float32(7), int64(3), object(8)\n",
      "memory usage: 127.9+ MB\n"
     ]
    }
   ],
   "source": [
    "test_raw.info(max_cols=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7734558 entries, 0 to 7734557\n",
      "Data columns (total 19 columns):\n",
      "event_id             object\n",
      "game_session         object\n",
      "timestamp            object\n",
      "event_data           object\n",
      "installation_id      object\n",
      "event_count          int64\n",
      "event_code           int64\n",
      "game_time            int64\n",
      "title                object\n",
      "type                 object\n",
      "world                object\n",
      "accuracy_group       float64\n",
      "ed.duration          float32\n",
      "ed.level             float32\n",
      "ed.round             float32\n",
      "ed.correct           float32\n",
      "ed.misses            float32\n",
      "ed.weight            float32\n",
      "ed.total_duration    float32\n",
      "dtypes: float32(7), float64(1), int64(3), object(8)\n",
      "memory usage: 914.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_raw.info(max_cols=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All event ids in test set also exist in train set\n",
    "#test_set = set(test_raw['event_id'])\n",
    "#train_set = set(train_raw['event_id'])\n",
    "#vs = test_set - train_set\n",
    "#_log(f'{len(vs)} event_ids exist in test set but not train set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379 EVENT_IDS=['0086365d', '00c73085', '01ca3a3c', '022b4259', '02a42007', '0330ab6a', '0413e89d', '04df9b66', '05ad839b', '06372577', '070a5291', '08fd73f3', '08ff79ad', '0a08139c', '0ce40006', '0d18d96c', '0d1da71f', '0db6d71d', '119b5b02', '1325467d', '1340b8d7', '1375ccb7', '13f56524', '14de4c5d', '155f62a4', '1575e76c', '15a43e5b', '15ba1109', '15eb4a7d', '15f99afc', '160654fd', '16667cc5', '16dffff1', '17113b36', '19967db1', '1996c610', '1af8be29', '1b54d27f', '1bb5fbdb', '1beb320a', '1c178d24', '1cc7cfca', '1cf54632', '1f19558b', '222660ff', '2230fab4', '250513af', '25fa8af4', '262136f4', '26a5a3dd', '26fd2d99', '27253bdc', '28520915', '28a4eb9a', '28ed704e', '28f975ea', '29a42aea', '29bdd9ba', '29f54413', '2a444e03', '2a512369', '2b058fe3', '2b9272f4', '2c4e6db0', '2dc29e21', '2dcad279', '2ec694de', '2fb91ec1', '30614231', '30df3273', '31973d56', '3323d7e9', '33505eae', '3393b68b', '363c86c9', '363d3849', '36fa3ebe', '37937459', '37c53127', '37db1c2f', '37ee8496', '38074c54', '392e14df', '3a4be871', '3afb49e6', '3afde5dd', '3b2048ee', '3babcb9b', '3bb91ced', '3bb91dda', '3bf1cf26', '3bfd1a65', '3ccd3f02', '3d0b9317', '3d63345e', '3d8c61b0', '3dcdda7f', '3ddc79c3', '3dfd4aa4', '3edf6747', '3ee399c3', '44cb4907', '45d01abe', '461eace6', '46b50ba8', '46cd75b4', '47026d5f', '47efca07', '47f43a44', '48349b14', '4901243f', '499edb7c', '49ed92e9', '4a09ace1', '4a4c3d21', '4b5efe37', '4bb2f698', '4c2ec19f', '4d6737eb', '4d911100', '4e5fc6f5', '4ef8cdd3', '51102b85', '51311d7a', '5154fc30', '5290eab1', '532a2afb', '5348fd84', '53c6e11a', '55115cbd', '562cec5f', '565a3990', '56817e2b', '56bcd38d', '56cd3b43', '5859dfb6', '587b5989', '58a0de5c', '598f4598', '5a848010', '5b49460a', '5be391b5', '5c2f29ca', '5c3d2b2f', '5d042115', '5de79a6a', '5e109ec3', '5e3ea25a', '5e812b27', '5f0eb72c', '5f5b2617', '6043a2b4', '6077cc36', '6088b756', '611485c5', '63f13dd7', '65a38bf7', '65abac75', '67439901', '67aa2ada', '69fdac0a', '6aeafed4', '6bf9e3e1', '6c517a88', '6c930e6e', '6cf7d25c', '6d90d394', '6f445b57', '6f4adc4b', '6f4bd64e', '6f8106d9', '7040c096', '709b1251', '71e712d8', '71fe8f75', '731c0cbe', '736f9581', '7372e1a5', '73757a5e', '7423acbc', '74e5f8a7', '7525289a', '756e5507', '763fc34e', '76babcde', '77261ab5', '77c76bc5', '77ead60d', '792530f8', '795e4a37', '7961e599', '7ab78247', '7ad3efc6', '7cf1bc53', '7d093bf9', '7d5c30a2', '7da34a02', '7dfe6d8a', '7ec0c298', '7f0836bf', '7fd1ac25', '804ee27f', '828e68f9', '832735e1', '83c6c409', '84538528', '84b0e0c8', '857f21c0', '85d1b0de', '85de926c', '86ba578b', '86c924c4', '87d743c1', '884228c8', '88d4a5be', '895865f3', '89aace00', '8ac7cce4', '8af75982', '8b757ab8', '8d748b58', '8d7e386c', '8d84fa81', '8f094001', '8fee50e2', '907a054b', '90d848e0', '90ea0bac', '90efca10', '91561152', '923afab1', '92687c59', '93b353f2', '93edfe2e', '9554a50b', '99abe2bb', '99ea62f3', '9b01374f', '9b23e8ee', '9b4001e4', '9c5ef70c', '9ce586dd', '9d29771f', '9d4e7b25', '9de5e594', '9e34ea74', '9e4c8c7b', '9e6b7fb5', '9ed8f6da', '9ee1c98c', 'a0faea5d', 'a1192f43', 'a16a373e', 'a1bbe385', 'a1e4395d', 'a29c5338', 'a2df0760', 'a44b10dc', 'a52b92d5', 'a592d54e', 'a5be6304', 'a5e9da97', 'a6d66e51', 'a76029ee', 'a7640a16', 'a8876db3', 'a8a78786', 'a8efe47b', 'ab3136ba', 'ab4ec3a4', 'abc5811c', 'ac92046e', 'acf5c23f', 'ad148f58', 'ad2fc29c', 'b012cd7f', 'b120f2ac', 'b1d5101d', 'b2dba42b', 'b2e5b0f1', 'b5053438', 'b74258a0', 'b7530680', 'b7dc8128', 'b80e5e84', 'b88f38da', 'bb3e370b', 'bbfe0445', 'bc8f2793', 'bcceccc6', 'bd612267', 'bd701df8', 'bdf49a58', 'beb0a7b9', 'bfc77bd6', 'c0415e5c', 'c189aaf2', 'c1cac9a2', 'c277e121', 'c2baf0bd', 'c51d8688', 'c54cf6c5', 'c58186bf', 'c6971acf', 'c7128948', 'c74f40cd', 'c7f7f0e1', 'c7fe2a55', 'c952eb01', 'ca11f653', 'cb1178ad', 'cb6010f8', 'cc5087a3', 'cdd22e43', 'cf7638f3', 'cf82af56', 'cfbd47c8', 'd02b7a8e', 'd06f75b5', 'd122731b', 'd185d3ea', 'd2278a3b', 'd2659ab4', 'd2e9262e', 'd3268efa', 'd3640339', 'd38c2fd7', 'd3f1e122', 'd45ed6a1', 'd51b1749', 'd88ca108', 'd88e8f25', 'd9c005dd', 'daac11b0', 'db02c830', 'dcaede90', 'dcb1663e', 'dcb55a27', 'de26c3a6', 'df4940d3', 'df4fe8b6', 'e04fb33d', 'e080a381', 'e37a2b78', 'e3ff61fb', 'e4d32835', 'e4f1efe6', 'e5734469', 'e57dd7af', 'e5c9df6f', 'e64e2cfd', 'e694a35b', 'e720d930', 'e7561dd2', 'e79f3763', 'e7e44842', 'e9c52111', 'ea296733', 'ea321fb1', 'eb2c19cd', 'ec138c1c', 'ecaab346', 'ecc36b7f', 'ecc6157f', 'f28c589a', 'f32856e4', 'f3cd5473', 'f50fc6c1', 'f54238ee', 'f56e0afc', 'f5b8c21a', 'f6947f54', 'f71c4741', 'f7e47413', 'f806dc10', 'f93fc684', 'fbaf3456', 'fcfdffb6', 'fd20ea40']\n"
     ]
    }
   ],
   "source": [
    "EVENT_IDS = sorted(list(set(train_raw['event_id']) | set(test_raw['event_id'])))\n",
    "_log(f'{len(EVENT_IDS)} EVENT_IDS={EVENT_IDS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bottle Filler (Activity)         112223\n",
       "Scrub-A-Dub                       96619\n",
       "Chow Time                         93142\n",
       "Sandcastle Builder (Activity)     82132\n",
       "Fireworks (Activity)              61032\n",
       "Bug Measurer (Activity)           59886\n",
       "Bubble Bath                       55264\n",
       "Dino Drink                        53989\n",
       "Dino Dive                         49368\n",
       "Crystals Rule                     46867\n",
       "Chicken Balancer (Activity)       45874\n",
       "All Star Sorting                  45863\n",
       "Flower Waterer (Activity)         43819\n",
       "Happy Camel                       39806\n",
       "Pan Balance                       38649\n",
       "Watering Hole (Activity)          35367\n",
       "Air Show                          27119\n",
       "Egg Dropper (Activity)            25941\n",
       "Leaf Leader                       25574\n",
       "Cauldron Filler (Assessment)      23440\n",
       "Mushroom Sorter (Assessment)      21962\n",
       "Bird Measurer (Assessment)        20086\n",
       "Cart Balancer (Assessment)        19235\n",
       "Chest Sorter (Assessment)         17904\n",
       "Crystal Caves - Level 2            1450\n",
       "Welcome to Lost Lagoon!            1441\n",
       "Magma Peak - Level 2               1434\n",
       "Tree Top City - Level 2            1277\n",
       "Crystal Caves - Level 3            1101\n",
       "Crystal Caves - Level 1             925\n",
       "Magma Peak - Level 1                903\n",
       "Tree Top City - Level 1             901\n",
       "Tree Top City - Level 3             842\n",
       "Ordering Spheres                    783\n",
       "Slop Problem                        552\n",
       "Lifting Heavy Things                535\n",
       "Balancing Act                       528\n",
       "Pirate's Tale                       463\n",
       "Honey Cake                          442\n",
       "12 Monkeys                          430\n",
       "Costume Box                         422\n",
       "Rulers                              320\n",
       "Heavy, Heavier, Heaviest            281\n",
       "Treasure Map                        223\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TITLES = test_raw['title'].unique()\n",
    "test_raw['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Game          572260\n",
       "Activity      466274\n",
       "Assessment    102627\n",
       "Clip           15253\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TYPES = test_raw['type'].unique()\n",
    "test_raw['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAGMAPEAK       511291\n",
       "TREETOPCITY     332295\n",
       "CRYSTALCAVES    311387\n",
       "NONE              1441\n",
       "Name: world, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORLDS = test_raw['world'].unique()\n",
    "test_raw['world'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_raw['ed.source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_raw['ed.identifier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 train_raw type=[2000, 2010, 2020, 2025, 2030, 2035, 2040, 2050, 2060, 2070, 2075, 2080, 2081, 2083, 3010, 3020, 3021, 3110, 3120, 3121, 4010, 4020, 4021, 4022, 4025, 4030, 4031, 4035, 4040, 4045, 4050, 4070, 4080, 4090, 4095, 4100, 4110, 4220, 4230, 4235, 5000, 5010]\n"
     ]
    }
   ],
   "source": [
    "vs = sorted(train_raw['event_code'].unique())\n",
    "_log(f'{len(vs)} train_raw type={vs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.33 s, sys: 278 ms, total: 4.61 s\n",
      "Wall time: 4.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_prev = pd.to_datetime(pd.Series(['2019-08-06T05:22:41.147000000'])).astype(np.int64).values[0]\n",
    "_next = pd.to_datetime(pd.Series(['2019-08-06T05:22:41.147000001'])).astype(np.int64).values[0]\n",
    "assert _next - _prev == 1\n",
    "\n",
    "\n",
    "def _transform_timestamp(df):\n",
    "    vs = pd.to_datetime(df['timestamp'])\n",
    "    df['timestamp'] = vs\n",
    "    assert df['timestamp'].notna().all()\n",
    "    df['timestamp_int'] = vs.astype(np.int64)\n",
    "    assert df['timestamp_int'].notna().all()\n",
    "\n",
    "\n",
    "_transform_timestamp(train_raw)\n",
    "_transform_timestamp(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.9 s, sys: 706 ms, total: 38.6 s\n",
      "Wall time: 38.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def _set_string_type(df, cols):\n",
    "    df[cols] = df[cols].astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "cols = ['event_code', 'timestamp']\n",
    "train_raw = _set_string_type(train_raw, cols=cols)\n",
    "test_raw = _set_string_type(test_raw, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def _sort_it(df):\n",
    "    return df.sort_values(by=['installation_id', 'timestamp'])\n",
    "\n",
    "\n",
    "#train_raw = _sort_it(train_raw)\n",
    "#test_raw = _sort_it(test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple accuracy groups per installation id\n",
    "In the training set, you are provided the full history of gameplay data. In the test set, we have truncated the history after the start event of a single assessment, chosen randomly, for which you must predict the number of attempts. Note that the training set contains many installation_ids which never took assessments, whereas every installation_id in the test set made an attempt on at least one assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       3\n",
       "2       1\n",
       "3       3\n",
       "4       1\n",
       "       ..\n",
       "3609    2\n",
       "3610    4\n",
       "3611    2\n",
       "3612    1\n",
       "3613    2\n",
       "Name: accuracy_group, Length: 3614, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs = train_raw[train_raw[TARGET].notna()].groupby('installation_id', as_index=False)[TARGET].nunique()\n",
    "vs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split not by time\n",
    "Both train and test sets span the same time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_log(f'train_raw[timestamp] is from {train_raw.timestamp.min()} to {train_raw.timestamp.max()}')\n",
    "#_log(f'test_raw[timestamp] is from {test_raw.timestamp.min()} to {test_raw.timestamp.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vs = train_raw[(train_raw['installation_id'] == '0006a69f') & (train_raw[TARGET].notna())].groupby(['game_session', 'title', TARGET], as_index=False)['timestamp'].max()\n",
    "#vs = sorted(vs['timestamp'].values) \n",
    "#vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>world</th>\n",
       "      <th>type</th>\n",
       "      <th>game_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0.25</th>\n",
       "      <td>CRYSTALCAVES</td>\n",
       "      <td>Activity</td>\n",
       "      <td>30166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>CRYSTALCAVES</td>\n",
       "      <td>Activity</td>\n",
       "      <td>68631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>CRYSTALCAVES</td>\n",
       "      <td>Activity</td>\n",
       "      <td>129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0.25</th>\n",
       "      <td>CRYSTALCAVES</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>8612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>CRYSTALCAVES</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>22373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               world        type  game_time\n",
       "0 0.25  CRYSTALCAVES    Activity      30166\n",
       "  0.50  CRYSTALCAVES    Activity      68631\n",
       "  0.75  CRYSTALCAVES    Activity     129000\n",
       "1 0.25  CRYSTALCAVES  Assessment       8612\n",
       "  0.50  CRYSTALCAVES  Assessment      22373"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tmp = test_raw.groupby(['world', 'type'], as_index=False)['game_time'].quantile([.25, .5, .75], interpolation='lower')\n",
    "#tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7734558 entries, 0 to 7734557\n",
      "Data columns (total 20 columns):\n",
      "event_id             object\n",
      "game_session         object\n",
      "timestamp            object\n",
      "event_data           object\n",
      "installation_id      object\n",
      "event_count          int64\n",
      "event_code           object\n",
      "game_time            int64\n",
      "title                object\n",
      "type                 object\n",
      "world                object\n",
      "accuracy_group       float64\n",
      "ed.duration          float32\n",
      "ed.level             float32\n",
      "ed.round             float32\n",
      "ed.correct           float32\n",
      "ed.misses            float32\n",
      "ed.weight            float32\n",
      "ed.total_duration    float32\n",
      "timestamp_int        int64\n",
      "dtypes: float32(7), float64(1), int64(3), object(9)\n",
      "memory usage: 973.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_raw.info(max_cols=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1156414 entries, 0 to 1156413\n",
      "Data columns (total 19 columns):\n",
      "event_id             1156414 non-null object\n",
      "game_session         1156414 non-null object\n",
      "timestamp            1156414 non-null object\n",
      "event_data           1156414 non-null object\n",
      "installation_id      1156414 non-null object\n",
      "event_count          1156414 non-null int64\n",
      "event_code           1156414 non-null object\n",
      "game_time            1156414 non-null int64\n",
      "title                1156414 non-null object\n",
      "type                 1156414 non-null object\n",
      "world                1156414 non-null object\n",
      "ed.duration          336619 non-null float32\n",
      "ed.level             84208 non-null float32\n",
      "ed.round             598718 non-null float32\n",
      "ed.correct           69806 non-null float32\n",
      "ed.misses            23658 non-null float32\n",
      "ed.weight            50353 non-null float32\n",
      "ed.total_duration    170228 non-null float32\n",
      "timestamp_int        1156414 non-null int64\n",
      "dtypes: float32(7), int64(3), object(9)\n",
      "memory usage: 136.8+ MB\n"
     ]
    }
   ],
   "source": [
    "test_raw.info(max_cols=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _key(s):\n",
    "    return re.sub(r'[\\W\\s]', '', s).lower()\n",
    "\n",
    "\n",
    "def _timestamp_cutoffs(df, TARGET):\n",
    "    res = df[df[TARGET].notna()].copy().groupby(['game_session', 'title', TARGET], as_index=False)['timestamp_int'].max()\n",
    "    res = sorted(res['timestamp_int'].values)\n",
    "    return res\n",
    "\n",
    "    \n",
    "def _target_variable(df, TARGET):\n",
    "    vs = df[TARGET].copy().dropna().unique()\n",
    "    assert len(set(vs)) == 1\n",
    "    return vs[0]\n",
    "    \n",
    "\n",
    "def _group_stats(df, col, titles, types, worlds, suffix):\n",
    "    \"\"\"Get percentile stats\"\"\"\n",
    "    res = {}\n",
    "    _percentiles = [0.25, 0.5, 0.75]\n",
    "    _default = -1\n",
    "    # initialize values\n",
    "    for p in _percentiles:\n",
    "        percentile = f'p{p * 100}'\n",
    "        for w in worlds:\n",
    "            for t in types:\n",
    "                k = f'{col}_{percentile}_{_key(w)}_{_key(t)}{suffix}'\n",
    "                res[k] = np.float32([_default])\n",
    "\n",
    "        for t in titles:\n",
    "            k = f'{col}_{percentile}_{_key(t)}{suffix}' \n",
    "            res[k] = np.float32([_default])\n",
    "\n",
    "    qs = df[col].quantile(_percentiles, interpolation='lower').to_numpy()\n",
    "    for i, q in enumerate(qs):\n",
    "        percentile = f'p{_percentiles[i] * 100}'\n",
    "        k = f'{col}_{percentile}{suffix}'\n",
    "        res[k] = np.float32([q])\n",
    "    \n",
    "    if len(worlds) != 0 and len(types) != 0:\n",
    "        tmp = df.groupby(['world', 'type'], as_index=False)[col].quantile(_percentiles, interpolation='lower')\n",
    "        i = 0\n",
    "        for row in tmp.itertuples(index=False):\n",
    "            percentile = f'p{_percentiles[i % 3] * 100}'\n",
    "            k = f'{col}_{percentile}_{_key(row[0])}_{_key(row[1])}{suffix}'\n",
    "            i += 1\n",
    "            if k in res and not np.isnan(row[2]):\n",
    "                res[k] = np.float32([row[2]])\n",
    "    \n",
    "    if len(titles) != 0:\n",
    "        tmp = df.groupby(['title'], as_index=False)[col].quantile(_percentiles, interpolation='lower')\n",
    "        i = 0\n",
    "        for row in tmp.itertuples(index=False):\n",
    "            percentile = f'p{_percentiles[i % 3] * 100}'\n",
    "            k = f'{col}_{percentile}_{_key(row[0])}{suffix}'\n",
    "            i += 1\n",
    "            if k in res and not np.isnan(row[1]):\n",
    "                res[k] = np.float32([row[1]])\n",
    "    return res    \n",
    "    \n",
    "\n",
    "def _game_session_stats(df, col, titles, types, worlds, suffix):\n",
    "    \"\"\"Deprecated.\"\"\"\n",
    "    res = {}\n",
    "    _default = -1\n",
    "    # initialize values\n",
    "    k = f'{col}_gamesession_p50{suffix}'\n",
    "    res[k] = np.float32([_default])\n",
    "    for w in worlds:\n",
    "        for t in types:\n",
    "            k = f'{col}_gamesession_{_key(w)}_{_key(t)}_p50{suffix}'\n",
    "            res[k] = np.float32([_default])\n",
    "\n",
    "    for t in titles:\n",
    "        k = f'{col}_gamesession_{_key(t)}_p50{suffix}' \n",
    "        res[k] = np.float32([_default])\n",
    "\n",
    "    tmp = df.groupby(['game_session'], as_index=False)[col].quantile(.75, interpolation='lower')\n",
    "    k = f'{col}_gamesession_p50{suffix}'\n",
    "    if k in res and not tmp[col].isna().all():\n",
    "        v = tmp[col].median()\n",
    "        res[k] = np.float32([v])\n",
    "\n",
    "    if len(worlds) != 0 and len(types) != 0:\n",
    "        tmp = df.groupby(['game_session', 'world', 'type'], as_index=False)[col].quantile(.75, interpolation='lower')\n",
    "        tmp.dropna(subset=[col], inplace=True)\n",
    "        tmp = tmp.groupby(['world', 'type'], as_index=False)[col].median()\n",
    "        for row in tmp.itertuples(index=False):\n",
    "            k = f'{col}_gamesession_{_key(row[0])}_{_key(row[1])}_p50{suffix}'\n",
    "            if k in res:\n",
    "                res[k] = np.float32([row[2]])\n",
    "\n",
    "    if len(titles) != 0:\n",
    "        tmp = df.groupby(['game_session', 'title'], as_index=False)[col].quantile(.75, interpolation='lower')\n",
    "        tmp.dropna(subset=[col], inplace=True)\n",
    "        tmp = tmp.groupby(['title'], as_index=False)[col].median()\n",
    "        for row in tmp.itertuples(index=False):\n",
    "            k = f'{col}_gamesession_{_key(row[0])}_p50{suffix}'\n",
    "            if k in res:\n",
    "                res[k] = np.float32([row[1]])\n",
    "    \n",
    "    #qs = vs.quantile([0.25, 0.5, 0.75], interpolation='lower').to_numpy()    \n",
    "    return res\n",
    "\n",
    "\n",
    "def _count(df, col, values, suffix):\n",
    "    res = {}\n",
    "    for v in values:\n",
    "        res[f'{col}_{_key(v)}{suffix}'] = np.int32([0])\n",
    "    \n",
    "    if len(values) != 0:\n",
    "        tmp = df.groupby([col], as_index=False).count()\n",
    "        for row in tmp.itertuples(index=False):\n",
    "            res[f'{col}_{_key(row[0])}{suffix}'] = np.int32([row[1]])\n",
    "    \n",
    "    return res\n",
    "    \n",
    "\n",
    "def _event_id_features(df, event_ids, titles, types, worlds, suffix):\n",
    "    res = {}\n",
    "    # initialize counts\n",
    "    for eid in event_ids:\n",
    "        res[f'eid_{eid}{suffix}'] = np.int32([0])      \n",
    "        for w in worlds:\n",
    "            for t in types:\n",
    "                res[f'eid_{eid}_{_key(w)}_{_key(t)}{suffix}'] = np.int32([0])\n",
    "            \n",
    "        for t in titles:\n",
    "            res[f'eid_{eid}_{_key(t)}{suffix}'] = np.int32([0])\n",
    "                      \n",
    "    tmp = df.groupby(['event_id'], as_index=False).count()\n",
    "    for row in tmp.itertuples(index=False):\n",
    "        res[f'eid_{row[0]}{suffix}'] = np.int32([row[1]])\n",
    "        \n",
    "    if len(worlds) != 0 and len(types) != 0:\n",
    "        tmp = df.groupby(['event_id', 'world', 'type'], as_index=False).count()\n",
    "        for row in tmp.itertuples(index=False):\n",
    "            k = f'eid_{row[0]}_{_key(row[1])}_{_key(row[2])}{suffix}'\n",
    "            if k in res:\n",
    "                res[k] = np.int32([row[3]])\n",
    "\n",
    "    if len(titles) != 0:\n",
    "        tmp = df.groupby(['event_id', 'title'], as_index=False).count()\n",
    "        for row in tmp.itertuples(index=False):\n",
    "            k = f'eid_{row[0]}_{_key(row[1])}{suffix}'\n",
    "            if k in res:\n",
    "                res[k] = np.int32([row[2]])\n",
    "        \n",
    "    return res\n",
    "\n",
    "\n",
    "def _event_code_features(df, event_codes, titles, types, worlds, suffix):\n",
    "    res = {}\n",
    "    # initialize counts\n",
    "    for code in event_codes:\n",
    "        res[f'event_{code}{suffix}'] = np.int32([0])\n",
    "        for w in worlds:\n",
    "            for t in types:\n",
    "                res[f'event_{code}_{_key(w)}_{_key(t)}{suffix}'] = np.int32([0])\n",
    "            \n",
    "        for t in titles:\n",
    "            res[f'event_{code}_{_key(t)}{suffix}'] = np.int32([0])\n",
    "        \n",
    "    tmp = df.groupby(['event_code'], as_index=False).count()\n",
    "    for row in tmp.itertuples(index=False):\n",
    "        res[f'event_{row[0]}{suffix}'] = np.int32([row[1]])\n",
    "        \n",
    "    if len(worlds) != 0 and len(types) != 0:\n",
    "        tmp = df.groupby(['event_code', 'world', 'type'], as_index=False).count()\n",
    "        for row in tmp.itertuples(index=False):\n",
    "            k = f'event_{row[0]}_{_key(row[1])}_{_key(row[2])}{suffix}'\n",
    "            if k in res:\n",
    "                res[k] = np.int32([row[3]])\n",
    "\n",
    "    if len(titles) != 0:\n",
    "        tmp = df.groupby(['event_code', 'title'], as_index=False).count()\n",
    "        for row in tmp.itertuples(index=False):\n",
    "            k = f'event_{row[0]}_{_key(row[1])}{suffix}'\n",
    "            if k in res:\n",
    "                res[k] = np.int32([row[2]])\n",
    "        \n",
    "    return res\n",
    "\n",
    "\n",
    "def _event_data_features(df, suffix):\n",
    "    res = {}\n",
    "    res[f'ed_duration{suffix}'] = np.int32(df['ed.duration'].fillna(0).max())\n",
    "    res[f'ed_total_duration{suffix}'] = np.int32(df['ed.total_duration'].fillna(0).max())\n",
    "    res[f'ed_level{suffix}'] = np.int32(df['ed.level'].fillna(0).max())\n",
    "    res[f'ed_round{suffix}'] = np.int32(df['ed.round'].fillna(0).max())\n",
    "    res[f'ed_correct{suffix}'] = np.int32(df['ed.correct'].fillna(0).max())\n",
    "    res[f'ed_misses{suffix}'] = np.int32(df['ed.misses'].fillna(0).max())\n",
    "    res[f'ed_weight{suffix}'] = np.int32(df['ed.weight'].fillna(0).max())\n",
    "    res[f'ed_source_resources{suffix}'] = np.int32([sum(df['ed.source'] == 'resources')])\n",
    "    res[f'ed_source_right{suffix}'] = np.int32([sum(df['ed.source'] == 'right')])\n",
    "    res[f'ed_source_left{suffix}'] = np.int32([sum(df['ed.source'] == 'left')])\n",
    "    res[f'ed_source_scale{suffix}'] = np.int32([sum(df['ed.source'] == 'scale')])\n",
    "    res[f'ed_source_middle{suffix}'] = np.int32([sum(df['ed.source'] == 'middle')])\n",
    "    res[f'ed_source_heaviest{suffix}'] = np.int32([sum(df['ed.source'] == 'Heaviest')])\n",
    "    res[f'ed_source_heavy{suffix}'] = np.int32([sum(df['ed.source'] == 'Heavy')])\n",
    "    res[f'ed_source_lightest{suffix}'] = np.int32([sum(df['ed.source'] == 'Lightest')])\n",
    "    n = 0\n",
    "    for i in range(1, 13):\n",
    "        n += sum(df['ed.source'] == str(i))\n",
    "    res[f'ed_source_numbered{suffix}'] = np.int32([n])\n",
    "    res[f'ed_id_dot{suffix}'] = np.int32([sum(df['ed.identifier'].str.contains('Dot_', regex=False))])\n",
    "    res[f'ed_id_buddy{suffix}'] = np.int32([sum(df['ed.identifier'].str.contains('Buddy_', regex=False))])\n",
    "    res[f'ed_id_cleo{suffix}'] = np.int32([sum(df['ed.identifier'].str.contains('Cleo_', regex=False))])\n",
    "    res[f'ed_id_mom{suffix}'] = np.int32([sum(df['ed.identifier'].str.contains('Mom_', regex=False))])\n",
    "    res[f'ed_id_sid{suffix}'] = np.int32([sum(df['ed.identifier'].str.contains('sid_', regex=False))])\n",
    "    positives = {'Dot_SoCool', 'Dot_GreatJob', 'ohWow', 'wowSoCool', 'thatLooksSoCool', 'tub_success', \n",
    "                 'water_success', 'soap_success', 'Dot_Amazing', 'Dot_WhoaSoCool', 'Dot_ThatsIt', 'youDidIt_1305',\n",
    "                 'SFX_completedtask', 'Cleo_AmazingPowers', 'RIGHTANSWER1', 'Dot_Awesome', 'greatJob_1306', 'YouDidIt',\n",
    "                 'RIGHTANSWER3', 'RIGHTANSWER2', 'INSTRCOMPLETE', 'AWESOME', 'WayToGoTeam', 'Dot_NiceWorkAllMatch',\n",
    "                 'GreatFlying', 'WeDidItOneRoundLeft', 'Cleo_AweOfYourSkills', 'Dot_NiceWork'}\n",
    "    n_pos = 0\n",
    "    for p in positives:\n",
    "        n_pos += sum(df['ed.identifier'].str.contains(p, regex=False))\n",
    "    res[f'ed_id_positive{suffix}'] = np.int32([n_pos])\n",
    "    negatives = {'Dot_Uhoh', 'Dot_UhOh', 'Dot_NeedTryAgain', 'IncorrectTooHeavy', 'Dot_GoLower', 'Buddy_TryDifferentNest',\n",
    "                 'Cleo_BowlTooLight', 'Dot_GoHigher', 'Dot_SoLow', 'Dot_SoHigh', 'Dot_WhoopsTooShort', 'IncorrectTooLight',\n",
    "                 'NOT_THAT_HEAVY', 'Dot_UhOhTooTall', 'ADD_MORE_WEIGHT', 'wrong1', 'tryAgain1', 'Dot_TryWeighingAgain',\n",
    "                 'Cleo_RememberHeavierBowl', 'Dot_Whoops', 'Dot_NotBalanced', 'Mom_TooManyContainers',\n",
    "                 'WrongOver', 'Mom_TooMuchWater', 'Dot_ThatBucketNotRight', 'Dot_TryAgain', 'wrongFewer', 'WrongBetweenCliff',\n",
    "                 'Mom_NeedMoreContainers', 'Dot_Try', 'Dot_HmTooSmall'}\n",
    "    n_neg = 1\n",
    "    for ne in negatives:\n",
    "        n_neg += sum(df['ed.identifier'].str.contains(ne, regex=False))\n",
    "    res[f'ed_id_negative{suffix}'] = np.int32([n_neg])\n",
    "    res[f'ed_id_positive_ratio{suffix}'] = np.float32([n_pos / n_neg])\n",
    "    return res\n",
    "    \n",
    "    \n",
    "def _worlds_picked():\n",
    "    return ['MAGMAPEAK', 'TREETOPCITY', 'CRYSTALCAVES']\n",
    "\n",
    "\n",
    "def _titles_picked():\n",
    "    return ['Cauldron Filler (Assessment)', 'Mushroom Sorter (Assessment)', 'Bird Measurer (Assessment)',\n",
    "            'Cart Balancer (Assessment)', 'Chest Sorter (Assessment)'\n",
    "           ]\n",
    "    \n",
    "\n",
    "def _types_picked():\n",
    "    return ['Assessment', 'Game']\n",
    "    \n",
    "        \n",
    "def _features_map(df, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS, suffix=''):\n",
    "    res = {}\n",
    "    worlds = _worlds_picked()\n",
    "    titles = _titles_picked()\n",
    "    types = _types_picked()\n",
    "    cols = ['game_time', 'event_count']\n",
    "    #cols = ['game_time', 'event_count', 'ed.duration', 'ed.level', 'ed.round','ed.correct','ed.misses','ed.weight','ed.total_duration']\n",
    "    for col in cols:\n",
    "        res.update(_group_stats(df, col, titles=titles, types=types, worlds=worlds, suffix=suffix))\n",
    "    \n",
    "    res.update(_count(df, col='type', values=TYPES, suffix=suffix))\n",
    "    res.update(_count(df, col='world', values=WORLDS, suffix=suffix))\n",
    "    res.update(_count(df, col='title', values=TITLES, suffix=suffix))\n",
    "    res.update(_event_code_features(df, EVENT_CODES, titles=titles, types=types, worlds=worlds, suffix=suffix))\n",
    "    res.update(_event_id_features(df, EVENT_IDS, titles=titles, types=types, worlds=worlds, suffix=suffix))\n",
    "    #res.update(_event_data_features(df, suffix))\n",
    "    return res\n",
    "\n",
    "\n",
    "def _features(df, installation_id, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS):\n",
    "    res = {}\n",
    "    if TARGET in df.columns:\n",
    "        res[TARGET] = np.int16([_target_variable(df, TARGET)])\n",
    "    res['installation_id'] = [installation_id]    \n",
    "    res.update(_features_map(df, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS))\n",
    "    return pd.DataFrame.from_dict(res)\n",
    "\n",
    "\n",
    "def _preprocess(raw, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS):\n",
    "    res = pd.DataFrame()\n",
    "    raw = raw.set_index('installation_id', drop=False)\n",
    "    iids = raw['installation_id'].unique()\n",
    "    prev_len = None\n",
    "    prev_cols = None\n",
    "    rv = 0\n",
    "    for iid in tqdm(iids):\n",
    "        whole = raw.loc[[iid]].copy()  # double square brackets return a Dataframe!\n",
    "        whole = whole.set_index('timestamp_int', drop=False)\n",
    "        dfs = []\n",
    "        if TARGET in whole.columns:\n",
    "            # train set: each installation id may contribute one or more examples.\n",
    "            _prev = pd.to_datetime(pd.Series(['1999-01-01T05:22:41.147000000'])).astype(np.int64).values[0]\n",
    "            for _curr in _timestamp_cutoffs(whole, TARGET):\n",
    "                df = whole.loc[_prev + 1:_curr]\n",
    "                dfs.append(df)\n",
    "                _prev = _curr\n",
    "        else:\n",
    "            # test set: each installation id contributes one example.\n",
    "            dfs.append(whole)\n",
    "        j = -1\n",
    "        if len(dfs) > 1:\n",
    "            j = int(RANDOM_VALUES[rv])\n",
    "            rv += 1\n",
    "        for i, df in enumerate(dfs):\n",
    "            if TARGET in df.columns:\n",
    "                installation_id = f'{iid}_{i + 1}'\n",
    "            else:\n",
    "                installation_id = iid\n",
    "            ex = _features(df, installation_id, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS)\n",
    "            if TARGET in df.columns:\n",
    "                if i == j:\n",
    "                    ex['_is_val'] = 0  # validation set\n",
    "                else:\n",
    "                    ex['_is_val'] = -1\n",
    "            prev_len = len(ex.columns) if prev_len is None else prev_len\n",
    "            prev_cols = set(ex.columns) if prev_cols is None else prev_cols\n",
    "            if len(ex.columns) != prev_len:\n",
    "                _diff = set(ex.columns) - prev_cols\n",
    "                raise ValueError(f'Number of columns must be the same. Difference found={_diff}')\n",
    "            prev_len = len(ex.columns)\n",
    "            res = pd.concat([res, ex], ignore_index=True)\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/1000 [00:00<06:27,  2.58it/s]\u001b[A\n",
      "  0%|          | 2/1000 [00:00<06:10,  2.69it/s]\u001b[A\n",
      "  0%|          | 3/1000 [00:01<05:55,  2.80it/s]\u001b[A\n",
      "  0%|          | 4/1000 [00:01<06:56,  2.39it/s]\u001b[A\n",
      "  0%|          | 5/1000 [00:01<06:28,  2.56it/s]\u001b[A\n",
      "  1%|          | 6/1000 [00:02<06:06,  2.71it/s]\u001b[A\n",
      "  1%|          | 7/1000 [00:02<05:58,  2.77it/s]\u001b[A\n",
      "  1%|          | 8/1000 [00:02<05:55,  2.79it/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-de7d523f0e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVENT_CODES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVENT_IDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTITLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTYPES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWORLDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-48480b4a79f6>\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(raw, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0minstallation_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstallation_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVENT_CODES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVENT_IDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTITLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTYPES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWORLDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mTARGET\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-48480b4a79f6>\u001b[0m in \u001b[0;36m_features\u001b[0;34m(df, installation_id, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'installation_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minstallation_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_features_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVENT_CODES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVENT_IDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTITLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTYPES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWORLDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/seahrh/kaggle-data-science-bowl-2019/venv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1203\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"only recognize index or columns for orient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/seahrh/kaggle-data-science-bowl-2019/venv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    409\u001b[0m             )\n\u001b[1;32m    410\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/seahrh/kaggle-data-science-bowl-2019/venv/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         ]\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/seahrh/kaggle-data-science-bowl-2019/venv/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/seahrh/kaggle-data-science-bowl-2019/venv/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1694\u001b[0;31m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mform_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1695\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/seahrh/kaggle-data-science-bowl-2019/venv/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mform_blocks\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   1742\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/seahrh/kaggle-data-science-bowl-2019/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4273\u001b[0m         \u001b[0;31m# There's no custom logic to be implemented in __getslice__, so it's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4274\u001b[0m         \u001b[0;31m# not overloaded intentionally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4275\u001b[0;31m         \u001b[0mgetitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4276\u001b[0m         \u001b[0mpromote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = _preprocess(test_raw, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info(max_cols=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "assert test.notna().all(axis=None)\n",
    "del test_raw\n",
    "gc.collect()\n",
    "test.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE: train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# budget of 4 seconds per iteration, or 4 hours total.\n",
    "train = _preprocess(train_raw, EVENT_CODES, EVENT_IDS, TITLES, TYPES, WORLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info(max_cols=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train.notna().all(axis=None)\n",
    "tmp = train.groupby(['_is_val'], as_index=False)['installation_id'].count()\n",
    "assert tmp.iloc[1]['installation_id'] >= 2000\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_raw, tmp\n",
    "gc.collect()\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet('train.parquet')\n",
    "test.to_parquet('test.parquet')\n",
    "_log(os.listdir(\".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = pd.read_parquet('train.parquet')\n",
    "test = pd.read_parquet('test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log_transform(df, cols):\n",
    "    df[cols] = np.float32(np.log(df[cols] + 1))\n",
    "\n",
    "\n",
    "#cols = list(set(test.columns.values) - {'installation_id'})\n",
    "#_log_transform(train, cols)\n",
    "#_log_transform(test, cols)\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def _scaling(dfs, cols, scaler=None):\n",
    "    scaler = sklearn.preprocessing.RobustScaler() if scaler is None else scaler\n",
    "    scaler.fit(dfs[0][cols])\n",
    "    for df in dfs:\n",
    "        df[cols] = np.float32(scaler.transform(df[cols]))\n",
    "        assert df.notna().all(axis=None)\n",
    "\n",
    "\n",
    "#scaler = sklearn.preprocessing.PowerTransformer()\n",
    "cols = list(set(test.columns.values) - {'installation_id', '_is_val'})\n",
    "_scaling([train, test], cols)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet('train_scaled.parquet')\n",
    "test.to_parquet('test_scaled.parquet')\n",
    "_log(os.listdir(\".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "[KS Test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = pd.read_parquet('train_scaled.parquet')\n",
    "test = pd.read_parquet('test_scaled.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _select_features(df1, df2, features, alpha):\n",
    "    res = []\n",
    "    for f in tqdm(features):\n",
    "        if ks_2samp(df1[f], df2[f]).pvalue > alpha:\n",
    "            res.append(f)\n",
    "    return res\n",
    "\n",
    "\n",
    "ALPHA = 0.2\n",
    "features = set(test.columns.values) - {'installation_id', '_is_val'}\n",
    "PREDICTORS = _select_features(train, test, features, ALPHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = sorted(list(features - set(PREDICTORS)))\n",
    "PREDICTORS = sorted(PREDICTORS)\n",
    "_log(f'alpha={ALPHA}, keep {len(PREDICTORS)}/{len(features)} features, drop {len(dropped)} features.\\nkeep={PREDICTORS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropped features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_log(f'drop={dropped}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "Approach: Stacking two models\n",
    "1. Binary classification - was the assessment solved or not?\n",
    "1. Regression on the number of attempts taken to solve the assessment\n",
    "\n",
    "Reason: `accuracy_group` labels '1', '2' and '3' are ordinal but not '0'. See https://www.kaggle.com/c/data-science-bowl-2019/discussion/124836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_solved'] = -1\n",
    "train['solved_attempts'] = -1\n",
    "train.loc[train[TARGET] == 0, ['is_solved']] = 0\n",
    "train.loc[train[TARGET] != 0, ['is_solved']] = 1\n",
    "train.loc[train[TARGET] == 3, ['solved_attempts']] = 1\n",
    "train.loc[train[TARGET] == 2, ['solved_attempts']] = 2\n",
    "train.loc[train[TARGET] == 1, ['solved_attempts']] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify whether assessment was solved or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_train_cls = train['is_solved']\n",
    "x_train_cls = train[PREDICTORS]\n",
    "p_split = PredefinedSplit(test_fold=train['_is_val'].values)\n",
    "model = lgb.LGBMClassifier(n_estimators=10000, reg_alpha=1, objective='binary')\n",
    "pipe = Pipeline([('model', model)])\n",
    "param_grid = {\n",
    "    'model__learning_rate': [0.001],\n",
    "    'model__min_child_samples': [100],\n",
    "    'model__colsample_bytree': [0.01]\n",
    "}\n",
    "cls = GridSearchCV(pipe, cv=p_split, param_grid=param_grid, scoring='f1')\n",
    "#cv.fit(x_train, y_train, model__early_stopping_rounds=200, model__verbose=500)\n",
    "cls.fit(x_train_cls, y_train_cls)\n",
    "assert cls.best_estimator_['model'].n_classes_ == 2\n",
    "_log(f\"\"\"F1 LGBMClassifier\n",
    "best_score_={cls.best_score_:.5f}\n",
    "best_params_={cls.best_params_}\n",
    "n_features={cls.best_estimator_['model'].n_features_}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(cls.best_estimator_['model'], max_num_features=100, figsize=(10, 30), title='Classification feature importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def _random_forest_classifier(x_train_cls, y_train_cls):\n",
    "    model = RandomForestClassifier(n_estimators=4000, max_features='log2')\n",
    "    pipe = Pipeline([('model', model)])\n",
    "    param_grid = {\n",
    "        'model__max_depth': [4],\n",
    "        'model__min_samples_leaf': [40]\n",
    "    }\n",
    "    rfc = GridSearchCV(pipe, cv=FOLDS, param_grid=param_grid, scoring='f1')\n",
    "    rfc.fit(x_train_cls, y_train_cls)\n",
    "    assert rfc.best_estimator_['model'].n_classes_ == 2\n",
    "    return rfc\n",
    "\n",
    "\n",
    "#rfc = _random_forest_classifier(x_train_cls, y_train_cls)\n",
    "#_log(f\"\"\"F1 RandomForestClassifier\n",
    "#best_score_={rfc.best_score_:.5f}\n",
    "#best_params_={rfc.best_params_}\n",
    "#n_features={rfc.best_estimator_['model'].n_features_}\n",
    "#\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression on the number of attempts to solve the assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rmse(y, y_pred):\n",
    "    return sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "\n",
    "SCORING = make_scorer(_rmse, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train[train['is_solved'] == 1]\n",
    "y_train = tmp['solved_attempts']\n",
    "x_train = tmp[PREDICTORS]\n",
    "p_split = PredefinedSplit(test_fold=tmp['_is_val'].values)\n",
    "\n",
    "split_df = tmp.groupby(['_is_val'], as_index=False)['installation_id'].count()\n",
    "assert split_df.iloc[1]['installation_id'] >= 1500\n",
    "split_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = lgb.LGBMRegressor(n_estimators=10000, reg_alpha=1)\n",
    "pipe = Pipeline([('model', model)])\n",
    "param_grid = {\n",
    "    'model__learning_rate': [0.001],\n",
    "    'model__min_child_samples': [100],\n",
    "    'model__colsample_bytree': [0.1]\n",
    "}\n",
    "cv = GridSearchCV(pipe, cv=p_split, param_grid=param_grid, scoring=SCORING)\n",
    "#cv.fit(x_train, y_train, model__early_stopping_rounds=200, model__verbose=500)\n",
    "cv.fit(x_train, y_train)\n",
    "_log(f\"\"\"RMSE LGBMRegressor\n",
    "best_score_={cv.best_score_:.5f}\n",
    "best_params_={cv.best_params_}\n",
    "n_features={cv.best_estimator_['model'].n_features_}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metric only works with early stopping rounds\n",
    "#lgb.plot_metric(cv.best_estimator_['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(cv.best_estimator_['model'], max_num_features=100, figsize=(10, 30), title='Regression feature importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def _random_forest_regressor(x_train, y_train):\n",
    "    model = RandomForestRegressor(n_estimators=4000, max_features='log2')\n",
    "    pipe = Pipeline([('model', model)])\n",
    "    param_grid = {\n",
    "        'model__max_depth': [4],\n",
    "        'model__min_samples_leaf': [40]\n",
    "    }\n",
    "    rfr = GridSearchCV(pipe, cv=FOLDS, param_grid=param_grid, scoring=SCORING)\n",
    "    rfr.fit(x_train, y_train)\n",
    "    return rfr\n",
    "\n",
    "\n",
    "#rfr = _random_forest_regressor(x_train, y_train)\n",
    "#_log(f\"\"\"RMSE RandomForestRegressor\n",
    "#best_score_={rfr.best_score_:.5f}\n",
    "#best_params_={rfr.best_params_}\n",
    "#n_features={rfr.best_estimator_['model'].n_features_}\n",
    "#\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict out of fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def _is_solved(score):\n",
    "    if score >= 0.6:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def _solved_attempts(score):\n",
    "    if score >= 2.5:  # 1.6\n",
    "        return 3\n",
    "    if score >= 1.5:\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "\n",
    "def _predict(df, classifiers, regressors):\n",
    "    res = df[['installation_id']].copy()\n",
    "    res[TARGET] = np.nan\n",
    "    x_cls = df[PREDICTORS]\n",
    "    res['is_solved'] = 0\n",
    "    for c, w, name in classifiers:\n",
    "        col = f'is_solved_{name}'\n",
    "        res[col] = c.predict_proba(x_cls)[:,1]\n",
    "        res['is_solved'] += res[col] * w\n",
    "    \n",
    "    res['is_solved'] = np.int16(res['is_solved'].map(_is_solved))\n",
    "    iids = set(res[res['is_solved'] == 1]['installation_id'].values)\n",
    "    cols = ['installation_id'] + PREDICTORS\n",
    "    tmp = df[df['installation_id'].isin(iids)][cols].copy()\n",
    "    x = tmp[PREDICTORS]\n",
    "    cols = ['installation_id', 'solved_attempts_raw', 'solved_attempts']\n",
    "    tmp['solved_attempts_raw'] = 0\n",
    "    for r, w, name in regressors:\n",
    "        col = f'solved_attempts_{name}'\n",
    "        cols.append(col)\n",
    "        tmp[col] = r.predict(x)\n",
    "        tmp['solved_attempts_raw'] += tmp[col] * w\n",
    "        \n",
    "    tmp['solved_attempts'] = np.int16(tmp['solved_attempts_raw'].map(_solved_attempts))\n",
    "    tmp = tmp[cols]\n",
    "    res = res.merge(tmp, on='installation_id', how='left')\n",
    "    res.loc[res['is_solved'] == 0, [TARGET]] = 0\n",
    "    res.loc[(res['is_solved'] == 1) & (res['solved_attempts'] >= 3), [TARGET]] = 1\n",
    "    res.loc[(res['is_solved'] == 1) & (res['solved_attempts'] == 2), [TARGET]] = 2\n",
    "    res.loc[(res['is_solved'] == 1) & (res['solved_attempts'] <= 1), [TARGET]] = 3\n",
    "    assert res[TARGET].notna().all(axis=None)\n",
    "    res[TARGET] = np.int16(res[TARGET])\n",
    "    return res\n",
    "\n",
    "\n",
    "classifiers=[\n",
    "    (cls, 1, 'LGBMClassifier')\n",
    "]\n",
    "regressors=[\n",
    "    (cv, 1, 'LGBMRegressor')\n",
    "]\n",
    "oof = _predict(train, classifiers=classifiers, regressors=regressors)\n",
    "oof.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.title('oof is_solved_LGBMClassifier')\n",
    "oof['is_solved_LGBMClassifier'].plot(kind='hist')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('oof solved_attempts_LGBMRegressor')\n",
    "oof['solved_attempts_LGBMRegressor'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof.sort_values(by=['installation_id'], inplace=True)\n",
    "train.sort_values(by=['installation_id'], inplace=True)\n",
    "y_true = train[TARGET]\n",
    "y_pred = oof[TARGET]\n",
    "kappa = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "_log(f'oof kappa={kappa:.5f}, acc={acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sub = _predict(test, classifiers=classifiers, regressors=regressors)\n",
    "sub = sub[['installation_id', TARGET]]\n",
    "sample_sub = pd.read_csv(f'{INPUT_ROOT}/sample_submission.csv')\n",
    "assert sub['installation_id'].equals(sample_sub['installation_id'])\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 3, 1)\n",
    "plt.title('test predict')\n",
    "sub[TARGET].plot(kind='hist')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('oof predict')\n",
    "oof[TARGET].plot(kind='hist')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('oof truth')\n",
    "tmp = train[TARGET].copy()\n",
    "tmp = tmp.astype(int)\n",
    "tmp.plot(kind='hist')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)\n",
    "_log(os.listdir(\".\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
